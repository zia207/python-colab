{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KsBkpmP_qjLM"
   },
   "source": [
    "![alt text](http://drive.google.com/uc?export=view&id=1IFEWet-Aw4DhkkVe1xv_2YYqlvRe9m5_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nQlXYe8YuRDo"
   },
   "source": [
    "# Generalized Linear Models\n",
    "\n",
    "Generalized Linear Models (GLMs) are a versatile class of models that extend linear regression to handle a variety of response variable distributions and relationships. n Python, GLMs are commonly implemented using the statsmodels library, which provides flexible tools for fitting various GLM families, providing a powerful framework for analyzing both continuous and categorical data across a wide range of contexts. This tutorial introduces several types of GLMs, as well as related models, and demonstrates how to implement each in Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dzp9ZseROTcY"
   },
   "source": [
    "##  Overview\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h0FPXx8mGylY"
   },
   "source": [
    "\n",
    "The Generalized Linear Model (GLM) is a sophisticated extension of linear regression designed to model relationships between a dependent variable and independent variables when the underlying assumptions of linear regression are unmet. The GLM was first introduced by Sir John Nelder and Robert Wedderburn, both acclaimed statisticians, in 1972.\n",
    "\n",
    "The GLM is an essential tool in modern data analysis, as it can be used to model a wide range of data types that may not conform to the assumptions of traditional linear regression. It allows for modeling non-normal distributions, non-linear relationships, and correlations between observations. By utilizing **maximum likelihood estimation (MLE)**, the GLM can also handle missing data and provide accurate estimates even when some observations are missing. This makes it a valuable tool in business and academia, where the ability to model complex relationships accurately is essential.\n",
    "\n",
    "The GLM is a powerful and flexible tool integral to modern data analysis. Its ability to model complex relationships between variables and handle missing data has made it a valuable asset in business and academia.\n",
    "\n",
    "**Maximum Likelihood Estimation (MLE)** is a statistical technique used to estimate the parameters of a model by analyzing the observed data. This method involves finding the optimal values for the model parameters by maximizing the likelihood function. The likelihood function measures how well the model can explain the observed data. The higher the likelihood function, the more accurate the model explains the data. MLE is widely used in fields such as finance, economics, and engineering to create models that can predict future outcomes based on the available data.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G31UbMNZmo_4"
   },
   "source": [
    "## Key features of Generalized Linear Models\n",
    "\n",
    "1.  **Link Function:** GLMs are characterized by a **link function** that connects the linear predictor, a combination of independent variables, to the mean of the dependent variable. This connection enables the estimation of the relationship between independent and dependent variables in a non-linear fashion.\n",
    "\n",
    "The selection of a link function in GLMs is contingent upon the nature of the data and the distribution of the response variable. The `identity` link function is utilized when the continuous response variable follows a normal distribution. The `logit` link function is employed when the response variable is binary, meaning it can only take on two values and follows a binomial distribution. The `log` link function is utilized when the response variable is count data and follows a Poisson distribution.\n",
    "\n",
    "Choosing an appropriate link function is a crucial aspect of modeling, as it impacts the interpretation of the estimated coefficients for independent variables. Therefore, a thorough understanding of the nature of the data and the response variable's distribution is necessary when selecting a link function.\n",
    "\n",
    "2.  **Distribution Family:** Unlike linear regression, which assumes a normal distribution for the residuals, GLMs allow for a variety of probability distributions for the response variable. The choice of distribution is based on the characteristics of the data. Commonly used distributions include:\n",
    "\n",
    "    -   **Normal distribution (Gaussian):** For continuous data.\n",
    "\n",
    "    -   **Binomial distribution:** For binary or dichotomous data.\n",
    "\n",
    "    -   **Poisson distribution:** For count data.\n",
    "\n",
    "    -   **Gamma distribution:** For continuous, positive, skewed data.\n",
    "\n",
    "3.  **Variance Function:** GLMs accommodate heteroscedasticity (unequal variances across levels of the independent variables) by allowing the variance of the response variable to be a function of the mean.\n",
    "\n",
    "4.  **Deviance:** Instead of using the sum of squared residuals as in linear regression, GLMs use deviance to measure lack of fit. Deviance compares the fit of the model to a saturated model (a model that perfectly fits the data).\n",
    "\n",
    "The **mathematical expression** of a Generalized Linear Model (GLM) involves the linear predictor, the link function, and the probability distribution of the response variable.\n",
    "\n",
    "Here's the general form of a GLM:\n",
    "\n",
    "1.  **Linear Predictor (η):**\n",
    "\n",
    "    $$ \\eta = \\beta_0 + \\beta_1x_1 + \\beta_2x_2 + \\ldots + \\beta_kx_k $$\n",
    "\n",
    "    where:\n",
    "\n",
    "-   $\\eta$ is the linear predictor,\n",
    "\n",
    "-   $\\beta_0, \\beta_1, \\ldots, \\beta_k$ are the coefficients,\n",
    "\n",
    "-   $x_1, x_2, \\ldots, x_k$ are the independent variables.\n",
    "\n",
    "2.  **Link Function (**g):\n",
    "\n",
    "$$ g(\\mu) = \\eta $$\n",
    "\n",
    "The link function connects the linear predictor to the mean of the response variable. It transforms the mean (μ) to the linear predictor (η). Common link functions include:\n",
    "\n",
    "-   Identity link (for normal distribution):\n",
    "\n",
    "$$ g(\\mu) = \\mu $$\n",
    "\n",
    "-   Logit link (for binary data in logistic regression):\n",
    "\n",
    "$$ g(\\mu) = log(\\frac{\\mu}{1-\\mu}) $$\n",
    "\n",
    "-   Log link(for Poisson regression):\n",
    "\n",
    "$$ g(\\mu) = \\log(\\mu )$$\n",
    "\n",
    "3.  **Probability Distribution:** The response variable follows a probability distribution from the exponential family. The distribution is chosen based on the nature of the data. Common choices include:\n",
    "\n",
    "    -   Normal distribution (Gaussian) for continuous data.\n",
    "\n",
    "    -   Binomial distribution for binary or dichotomous data.\n",
    "\n",
    "    -   Poisson distribution for count data.\n",
    "\n",
    "    -   Gamma distribution for continuous, positive, skewed data.\n",
    "\n",
    "Putting it all together, the probability mass function (PMF) or probability density function (PDF) for the response variable (Y) is expressed as:\n",
    "\n",
    "$$ f(y;\\theta,\\phi) = \\exp\\left(\\frac{y\\theta - b(\\theta)}{a(\\phi)} + c(y,\\phi)\\right) $$\n",
    "\n",
    "where:\n",
    "\n",
    "-   f(y;θ,ϕ) is the PMF or PDF,\n",
    "\n",
    "-   θ is the natural parameter,\n",
    "\n",
    "-   ϕ is the dispersion parameter,\n",
    "\n",
    "-   a(ϕ), b(θ), c(y,ϕ) are known functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6b4_fnspfnyK"
   },
   "source": [
    "## Linear Regression vs Generalized Linear Models\n",
    "\n",
    "The primary difference between linear models (LM) and generalized linear models (GLM) is in their flexibility to handle different types of response variables and error distributions. Here’s a breakdown of the key distinctions:\n",
    "\n",
    "### 1. **Type of Response Variable**\n",
    "\n",
    "-   **LM (Linear Model)**: Assumes that the response variable is continuous and normally distributed. For example, predicting a continuous variable like height or weight.\n",
    "-   **GLM (Generalized Linear Model)**: Extends linear models to accommodate response variables that are not normally distributed, such as binary outcomes (0 or 1), counts, or proportions. GLMs can handle a variety of distributions (e.g., binomial, Poisson).\n",
    "\n",
    "### 2. **Link Function**\n",
    "\n",
    "-   **LM**: The relationship between the predictor variables and the response is assumed to be linear, with an identity link function (i.e., ($Y = X \\beta + \\epsilon$), where ($\\epsilon$) is normally distributed).\n",
    "-   **GLM**: Uses a link function to transform the linear predictor to accommodate different types of response variables. Common link functions include:\n",
    "    -   **Logit link** for binary data (logistic regression)\n",
    "    -   **Log link** for count data (Poisson regression)\n",
    "    -   **Identity link** for normal data (same as in LM)\n",
    "\n",
    "### 3. **Error Distribution**\n",
    "\n",
    "-   **LM**: Assumes errors are normally distributed with constant variance (homoscedasticity).\n",
    "-   **GLM**: Allows for different error distributions (e.g., binomial, Poisson, gamma) to better suit the data.\n",
    "\n",
    "### 4. **Use Cases**\n",
    "\n",
    "-   **LM**: Used when the response variable is continuous, normally distributed, and has a linear relationship with predictors.\n",
    "-   **GLM**: Used when the response variable does not fit these assumptions, such as binary outcomes (yes/no), counts, or proportions.\n",
    "\n",
    "### 5. **Examples**\n",
    "\n",
    "-   **LM**: Simple linear regression, multiple linear regression\n",
    "-   **GLM**: Logistic regression, Poisson regression, negative binomial regression, etc.\n",
    "\n",
    "In summary, GLMs generalize LMs by allowing for non-normal distributions and providing flexibility with link functions, making them more suitable for a wider range of data types and applications.\n",
    "\n",
    "In summary, the GLM combines the linear predictor, link function, and probability distribution to model the relationship between the mean of the response variable and the predictors, allowing for flexibility in handling various data types. The specific form of the GLM will depend on the chosen link function and distribution.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0UzCmbKxl-5F"
   },
   "source": [
    "## GLM Models with Python\n",
    "\n",
    "To implement Generalized Linear Models (GLMs) and their equivalents in Python, you can use several packages that provide functionality similar to R’s `stats`, `MASS`, `mgcv`, `betareg`, and `nnet`. Below, I outline how to perform GLM modeling in Python and identify Python packages equivalent to the R packages mentioned, along with examples for each model type.\n",
    "\n",
    "### Python Packages for GLM and Related Models\n",
    "\n",
    "1. **R’s `stats` Equivalent**:\n",
    "   - **Python Package**: `statsmodels`\n",
    "   - **Description**: `statsmodels` is the primary Python library for fitting GLMs, offering support for various GLM families (e.g., Gaussian, binomial, Poisson) and link functions. It is similar to R’s `stats` package for basic GLM modeling.\n",
    "   - **Installation**: `pip install statsmodels`\n",
    "\n",
    "2. **R’s `MASS` Equivalent (for ordinal regression)**:\n",
    "   - **Python Package**: `statsmodels` or `mord`\n",
    "   - **Description**: `statsmodels` supports ordinal regression via `OrderedModel`, which is equivalent to `MASS::polr` in R. Alternatively, the `mord` package provides additional ordinal regression models.\n",
    "   - **Installation**: `pip install statsmodels mord`\n",
    "\n",
    "3. **R’s `mgcv` Equivalent (for Generalized Additive Models)**:\n",
    "   - **Python Package**: `pygam`\n",
    "   - **Description**: `pygam` is a Python library for Generalized Additive Models (GAMs), offering functionality similar to R’s `mgcv` for fitting smooth, non-linear relationships.\n",
    "   - **Installation**: `pip install pygam`\n",
    "\n",
    "4. **R’s `betareg` Equivalent (for Beta regression)**:\n",
    "   - **Python Package**: No direct equivalent exists in Python, but `statsmodels` can be used to implement Beta regression with custom implementations or approximations. Alternatively, you can use `scipy` for optimization or `glum` for experimental Beta regression support.\n",
    "   - **Installation**: `pip install statsmodels glum`\n",
    "\n",
    "5. **R’s `nnet` Equivalent (for multinomial logistic regression)**:\n",
    "   - **Python Package**: `scikit-learn`\n",
    "   - **Description**: `scikit-learn` provides `LogisticRegression` with the `multi_class='multinomial'` option, which is equivalent to `nnet::multinom` for multinomial logistic regression.\n",
    "   - **Installation**: `pip install scikit-learn`\n",
    "\n",
    "### GLM Models in Python with Examples\n",
    "\n",
    "Below are Python equivalents for each of the R GLM models mentioned, using a sample dataset. For demonstration, assume `data` is a pandas DataFrame with columns `y` (response variable) and `x1`, `x2` (predictors).\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from pygam import LinearGAM, s\n",
    "from mord import LogisticAT\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Example dataset (replace with your own)\n",
    "np.random.seed(42)\n",
    "data = pd.DataFrame({\n",
    "    'y': np.random.normal(0, 1, 100),\n",
    "    'x1': np.random.normal(0, 1, 100),\n",
    "    'x2': np.random.normal(0, 1, 100)\n",
    "})\n",
    "```\n",
    "\n",
    "#### 1. Generalized Linear Regression (Gaussian)\n",
    "Equivalent to R’s `glm(y ~ x1 + x2, family = gaussian)`.\n",
    "\n",
    "```python\n",
    "# Gaussian GLM (Linear Regression)\n",
    "model_gaussian = smf.glm('y ~ x1 + x2', data=data, family=sm.families.Gaussian()).fit()\n",
    "print(model_gaussian.summary())\n",
    "```\n",
    "\n",
    "#### 2. Logistic Regression (Binary)\n",
    "For binary outcomes, equivalent to R’s `glm(y ~ x1 + x2, family = binomial)`.\n",
    "\n",
    "```python\n",
    "# Example with binary outcome\n",
    "data['y_binary'] = (data['y'] > 0).astype(int)  # Create binary outcome\n",
    "model_logistic = smf.glm('y_binary ~ x1 + x2', data=data, family=sm.families.Binomial()).fit()\n",
    "print(model_logistic.summary())\n",
    "```\n",
    "\n",
    "#### 3. Probit Regression\n",
    "Equivalent to R’s `glm(y ~ x1 + x2, family = binomial(link = \"probit\"))`.\n",
    "\n",
    "```python\n",
    "# Probit regression\n",
    "model_probit = smf.glm('y_binary ~ x1 + x2', data=data, family=sm.families.Binomial(link=sm.families.links.Probit())).fit()\n",
    "print(model_probit.summary())\n",
    "```\n",
    "\n",
    "#### 4. Ordinal Regression\n",
    "Equivalent to R’s `MASS::polr`. Use `statsmodels` or `mord`.\n",
    "\n",
    "```python\n",
    "# Example with ordinal outcome (e.g., 1, 2, 3)\n",
    "data['y_ordinal'] = pd.cut(data['y'], bins=3, labels=[1, 2, 3]).astype(int)\n",
    "from statsmodels.miscmodels.ordinal_model import OrderedModel\n",
    "model_ordinal = OrderedModel(data['y_ordinal'], data[['x1', 'x2']], distr='logit').fit()\n",
    "print(model_ordinal.summary())\n",
    "```\n",
    "\n",
    "#### 5. Multinomial Logistic Regression\n",
    "Equivalent to R’s `nnet::multinom`. Use `scikit-learn`.\n",
    "\n",
    "```python\n",
    "# Example with multinomial outcome\n",
    "data['y_multinom'] = pd.cut(data['y'], bins=3, labels=[0, 1, 2]).astype(int)\n",
    "X = data[['x1', 'x2']]\n",
    "y = data['y_multinom']\n",
    "model_multinom = LogisticRegression(multi_class='multinomial', solver='lbfgs').fit(X, y)\n",
    "print(\"Coefficients:\", model_multinom.coef_)\n",
    "```\n",
    "\n",
    "#### 6. Poisson Regression\n",
    "Equivalent to R’s `glm(y ~ x1 + x2, family = poisson)`.\n",
    "\n",
    "```python\n",
    "# Example with count data\n",
    "data['y_count'] = np.random.poisson(5, 100)  # Simulated count data\n",
    "model_poisson = smf.glm('y_count ~ x1 + x2', data=data, family=sm.families.Poisson()).fit()\n",
    "print(model_poisson.summary())\n",
    "```\n",
    "\n",
    "#### 7. Gamma Regression\n",
    "Equivalent to R’s `glm(y ~ x1 + x2, family = Gamma(link = \"log\"))`.\n",
    "\n",
    "```python\n",
    "# Example with positive continuous data\n",
    "data['y_positive'] = np.exp(data['y'])  # Ensure positive values\n",
    "model_gamma = smf.glm('y_positive ~ x1 + x2', data=data, family=sm.families.Gamma(link=sm.families.links.Log())).fit()\n",
    "print(model_gamma.summary())\n",
    "```\n",
    "\n",
    "#### 8. Beta Regression\n",
    "No direct equivalent in `statsmodels`, but `glum` or custom implementations can be used. Here’s an example using `statsmodels` with a custom approach (assuming `y` is between 0 and 1).\n",
    "\n",
    "```python\n",
    "# Example with data bounded between 0 and 1\n",
    "data['y_beta'] = (data['y'] - data['y'].min()) / (data['y'].max() - data['y'].min())  # Scale to (0,1)\n",
    "# Note: For proper Beta regression, use `glum` or custom optimization\n",
    "from glum import GeneralizedLinearRegressor\n",
    "model_beta = GeneralizedLinearRegressor(family=\"beta\", link=\"logit\").fit(data[['x1', 'x2']], data['y_beta'])\n",
    "print(\"Coefficients:\", model_beta.coef_)\n",
    "```\n",
    "\n",
    "#### 9. Generalized Additive Model (GAM)\n",
    "Equivalent to R’s `mgcv::gam`. Use `pygam`.\n",
    "\n",
    "```python\n",
    "# GAM with smooth terms\n",
    "X = data[['x1', 'x2']].values\n",
    "y = data['y'].values\n",
    "model_gam = LinearGAM(s(0) + s(1)).fit(X, y)\n",
    "print(model_gam.summary())\n",
    "```\n",
    "\n",
    "### Notes\n",
    "- **Data Preparation**: Ensure your data is appropriately scaled or transformed (e.g., for Beta regression, values must be strictly between 0 and 1).\n",
    "- **Link Functions**: `statsmodels` supports various link functions (e.g., `logit`, `probit`, `log`) similar to R’s `family` objects. Check `statsmodels.families.links` for available options.\n",
    "- **No Direct Beta Regression**: Python lacks a direct equivalent to R’s `betareg`. You may need to use `glum` or implement a custom likelihood function for precise Beta regression.\n",
    "- **Dependencies**: Install all required packages using `pip install pandas numpy statsmodels scikit-learn pygam mord glum`.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GyCRAq4sSM7p"
   },
   "source": [
    "## Summary and Conlusions\n",
    "\n",
    "The notebook begins by introducing GLMs as a powerful extension of linear regression, capable of handling various response variable distributions beyond the normal distribution assumed in traditional linear models. Key features of GLMs such as the link function, distribution family, variance function, and deviance are explained in detail, along with the mathematical expression of a GLM. The notebook also clearly contrasts Linear Models and Generalized Linear Models, highlighting their key differences in handling response variable types, link functions, and error distributions.\n",
    "\n",
    "The latter part of the notebook focuses on the practical implementation of GLMs and related models in Python. It identifies equivalent Python packages for common R packages used in GLM modeling (stats, MASS, mgcv, betareg, and nnet). For each type of GLM discussed (Gaussian, Logistic, Probit, Ordinal, Multinomial Logistic, Poisson, Gamma, Beta, and Generalized Additive Model), the notebook provides Python code examples using libraries like statsmodels, scikit-learn, and pygam.\n",
    "\n",
    "\n",
    "This notebook serves as an excellent resource for understanding and implementing Generalized Linear Models in Python. It effectively bridges the gap between the theoretical concepts of GLMs and their practical application using popular Python libraries. By providing clear explanations, code examples for various GLM types, and a curated list of additional resources, the notebook empowers users to apply these versatile models to a wide range of data analysis tasks, particularly when dealing with non-normally distributed response variables. While acknowledging the lack of a direct equivalent for Beta regression in core Python libraries like statsmodels, the notebook suggests alternative approaches using glum or custom implementations, demonstrating a thorough understanding of the available tools and their limitations. Overall, this notebook is a valuable guide for anyone looking to expand their statistical modeling skills beyond traditional linear regression.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UKrg91T3Rf1x"
   },
   "source": [
    "## Further Reading and Resources\n",
    "\n",
    "Here are some resources for further reading on Generalized Linear Models (GLMs) and their implementation in Python, covering both theoretical understanding and practical applications:\n",
    "\n",
    "### Books\n",
    "1. **\"Generalized Linear Models\" by P. McCullagh and J.A. Nelder**\n",
    "   - A foundational text on GLMs, covering theory, model families, and applications. Ideal for understanding the mathematical underpinnings.\n",
    "   - Available at: Major bookstores or libraries (e.g., Amazon, WorldCat).\n",
    "\n",
    "2. **\"An Introduction to Statistical Learning\" by Gareth James, Daniela Witten, Trevor Hastie, and Robert Tibshirani**\n",
    "   - Chapter 4 covers logistic regression and GLMs in an accessible way, with Python examples in the accompanying Python edition.\n",
    "   - Free PDF: [https://www.statlearning.com/](https://www.statlearning.com/)\n",
    "\n",
    "3. **\"Python for Data Analysis\" by Wes McKinney**\n",
    "   - Focuses on data manipulation with pandas and statistical modeling with `statsmodels`, including GLMs.\n",
    "   - Available at: O’Reilly Media or Amazon.\n",
    "\n",
    "4. **\"Generalized Additive Models: An Introduction with R\" by Simon N. Wood**\n",
    "   - While R-focused, it provides deep insights into GAMs, which can be applied to Python’s `pygam`. Useful for understanding smooth functions.\n",
    "   - Available at: CRC Press or Amazon.\n",
    "\n",
    "### Online Tutorials and Documentation\n",
    "1. **Statsmodels Documentation**\n",
    "   - Comprehensive guide to `statsmodels` for GLMs, including Gaussian, logistic, Poisson, and more, with examples.\n",
    "   - Link: [https://www.statsmodels.org/stable/glm.html](https://www.statsmodels.org/stable/glm.html)\n",
    "\n",
    "2. **PyGAM Documentation**\n",
    "   - Detailed resource for Generalized Additive Models in Python, covering installation, usage, and advanced features.\n",
    "   - Link: [https://pygam.readthedocs.io/en/latest/](https://pygam.readthedocs.io/en/latest/)\n",
    "\n",
    "3. **Scikit-learn Logistic Regression**\n",
    "   - Covers multinomial logistic regression and other classification techniques with practical Python examples.\n",
    "   - Link: [https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression](https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression)\n",
    "\n",
    "4. **Towards Data Science Articles**\n",
    "   - Search for GLM-related tutorials on Medium’s Towards Data Science, such as “A Gentle Introduction to Generalized Linear Models with Python” or similar articles.\n",
    "   - Link: [https://towardsdatascience.com/](https://towardsdatascience.com/)\n",
    "\n",
    "### Online Courses\n",
    "1. **Coursera: Statistical Modeling for Data Science Applications (University of Colorado Boulder)**\n",
    "   - Covers GLMs, logistic regression, and GAMs with Python examples using `statsmodels` and `pygam`.\n",
    "   - Link: [https://www.coursera.org/](https://www.coursera.org/)\n",
    "\n",
    "2. **DataCamp: Generalized Linear Models in Python**\n",
    "   - Hands-on course focusing on GLMs with `statsmodels`, including logistic, Poisson, and Gamma regression.\n",
    "   - Link: [https://www.datacamp.com/](https://www.datacamp.com/)\n",
    "\n",
    "### Blogs and Practical Guides\n",
    "1. **Real Python: Logistic Regression in Python**\n",
    "   - A beginner-friendly guide to implementing logistic regression with `statsmodels` and `scikit-learn`.\n",
    "   - Link: [https://realpython.com/logistic-regression-python/](https://realpython.com/logistic-regression-python/)\n",
    "\n",
    "2. **Machine Learning Mastery: GLMs in Python**\n",
    "   - Practical tutorials on GLMs and related models using Python, with code examples.\n",
    "   - Link: [https://machinelearningmastery.com/](https://machinelearningmastery.com/)\n",
    "\n",
    "3. **Kaggle Notebooks**\n",
    "   - Search Kaggle for GLM-related notebooks in Python, which often include real-world datasets and code for logistic, Poisson, and other models.\n",
    "   - Link: [https://www.kaggle.com/notebooks](https://www.kaggle.com/notebooks)\n",
    "\n",
    "### GitHub Repositories\n",
    "1. **Statsmodels Examples**\n",
    "   - Official `statsmodels` repository with example notebooks for GLMs and other statistical models.\n",
    "   - Link: [https://github.com/statsmodels/statsmodels](https://github.com/statsmodels/statsmodels)\n",
    "\n",
    "2. **PyGAM Examples**\n",
    "   - GitHub repository with tutorials and examples for fitting GAMs in Python.\n",
    "   - Link: [https://github.com/dswah/pyGAM](https://github.com/dswah/pyGAM)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    ". [Generalized Linear Regression (Gaussian)](https://github.com/zia207/r-colab/blob/main/NoteBook/Advance_Regression/02-01-01-glm-regression-r.ipynb)\n",
    "\n",
    "2. [Logistic Regression (Binary)](https://github.com/zia207/r-colab/blob/main/NoteBook/Advance_Regression/02-01-02-glm-logistic-r.ipynb)\n",
    "\n",
    "3. [Probit Regression Model](https://github.com/zia207/r-colab/blob/main/NoteBook/Advance_Regression/02-01-03-glm-probit-r.ipynb)\n",
    "\n",
    "4. [Ordinal Regression](https://github.com/zia207/r-colab/blob/main/NoteBook/Advance_Regression/02-01-04-glm-ordinal-r.ipynb)\n",
    "\n",
    "5. [Multinomial Logistic Regression](https://github.com/zia207/r-colab/blob/main/NoteBook/Advance_Regression/02-01-05-glm-multinomial-logistic-r.ipynb)\n",
    "\n",
    "6. [Poisson Regression ](https://github.com/zia207/r-colab/blob/main/NoteBook/Advance_Regression/02-01-06-00-poisson-regression-introduction-r.ipynb)\n",
    "\n",
    "  6.1. [Standard Poisson Regression (count data)](https://github.com/zia207/r-colab/blob/main/NoteBook/Advance_Regression/02-01-06-01-poisson-regression-standard-r.ipynb)\n",
    "\n",
    "  6.2.[Poisson Regression Model with Offset (rate data)](https://github.com/zia207/r-colab/blob/main/NoteBook/Advance_Regression/02-01-06-02-poisson-regression-offset-r.ipynb)\n",
    "\n",
    "  6.3. [Poisson Regression Models for Overdispersed Data](https://github.com/zia207/r-colab/blob/main/NoteBook/Advance_Regression/02-01-06-03-poisson-regression-overdispersion-r.ipynb)\n",
    "\n",
    "  6.4. [Zero-Inflated Models](https://github.com/zia207/r-colab/blob/main/NoteBook/Advance_Regression/02-01-06-04-poisson-regression-zeroinflated-r.ipynb)\n",
    "\n",
    " 6.5. [Hurdle Model](https://github.com/zia207/r-colab/blob/main/NoteBook/Advance_Regression/02-01-06-05-poisson-regression-hurdle-r.ipynb)\n",
    "\n",
    "\n",
    "7. [Gamma Regression](https://github.com/zia207/r-colab/blob/main/NoteBook/Advance_Regression/02-01-07-glm-gamma-regression-r.ipynb)\n",
    "\n",
    "8. [Beta Regression](https://github.com/zia207/r-colab/blob/main/NoteBook/Advance_Regression/02-01-08-glm-gamma-regression-r.ipynb)\n",
    "\n",
    "9. [Generalized Additive Model (GAM) ](https://github.com/zia207/r-colab/blob/main/NoteBook/Advance_Regression/02-02-09-glm-gam-regression.ipynb)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNJrvJuUQAwoXa2YfO0KNeY",
   "provenance": [
    {
     "file_id": "1J3qbKWO9p7dqXUJegN4oQynBiLom3QhD",
     "timestamp": 1754665754436
    },
    {
     "file_id": "1fY1F_9NOkD5ETMIi6YcHqRsBGWF8HxJ6",
     "timestamp": 1730169016639
    },
    {
     "file_id": "https://github.com/zia207/r-colab/blob/main/NoteBook/Advance_Regression/glm_regression_r.ipynb",
     "timestamp": 1726079201018
    }
   ],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "R",
   "name": "ir"
  },
  "language_info": {
   "name": "R"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
