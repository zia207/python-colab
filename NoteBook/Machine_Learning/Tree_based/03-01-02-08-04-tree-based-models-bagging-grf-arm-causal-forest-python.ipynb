{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zia207/python-colab/blob/main/NoteBook/Machine_Learning/Tree_based/03-01-02-08-04-tree-based-models-bagging-grf-arm-causal-forest-python.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zYZbTX0qQrZb"
      },
      "source": [
        "![alt text](http://drive.google.com/uc?export=view&id=1IFEWet-Aw4DhkkVe1xv_2YYqlvRe9m5_)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RGBfrL2GQoII"
      },
      "source": [
        "# 2.8.4 Multi-arm/multi-outcome Causal Forest\n",
        "\n",
        "A **Multi-Arm/Multi-Outcome Causal Forest** is an extension of the **Causal Forest** framework designed to estimate heterogeneous treatment effects in scenarios with **multiple treatment arms** (e.g., different interventions) and/or **multiple outcome variables** simultaneously. It builds on random forest principles to provide flexible, data-driven estimates of causal effects across diverse subgroups, leveraging shared information across treatments or outcomes to improve accuracy. This approach is particularly useful in complex experimental designs, such as clinical trials with multiple drugs or policy evaluations with various interventions affecting multiple metrics."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S77MsgmqIYD0"
      },
      "source": [
        "## Overview\n",
        "\n",
        "A multi-arm/multi-outcome causal forest is an advanced A multi-arm/multi-outcome causal forest is an advanced machine learning method for estimating heterogeneous treatment effects (HTE) in settings with:\n",
        "\n",
        "-   `Multiple treatments (multi-arm)`: More than two possible interventions or choices, not just \"treatment\" and \"control\".\n",
        "\n",
        "-   `Multiple outcomes (multi-outcome)`: Several different outcome variables of interest, not just a single outcome.\n",
        "\n",
        "Estimates causal effects (treatment effects) for multiple treatments (arms) or multiple outcomes in a single model, accounting for heterogeneity across covariates (e.g., patient characteristics). It answers questions like: \"How does each treatment affect different outcomes across different subgroups?\" Handles multiple treatment options (e.g., drug A, drug B, placebo) instead of a single treatment vs. control.\n",
        "\n",
        "-   Use Cases:\n",
        "\n",
        "  -   Clinical trials comparing multiple drugs on multiple health outcomes.\n",
        "  -   Policy evaluation with several interventions and diverse impacts (e.g., education programs affecting test scores and attendance).\n",
        "  -   Marketing studies analyzing multiple campaign strategies on various customer metrics.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VwEoykvwI2dS"
      },
      "source": [
        "### How It Work\n",
        "\n",
        "The Multi-Arm/Multi-Outcome Causal Forest builds on the **Generalized Random Forest (GRF)** framework, extending the Causal Forest algorithm (designed for single treatment/outcome) to handle multiple treatments and outcomes. Hereâ€™s a step-by-step explanation of its mechanics:\n",
        "\n",
        "1.  Data Setup\n",
        "\n",
        "  -   A dataset with:\n",
        "  -   Covariates $X$ (e.g., patient age, gender).\n",
        "  -   Treatment assignments $W$, where $W$ can take multiple values (e.g., 0 for control, 1 for treatment A, 2 for treatment B).\n",
        "  -   Multiple outcome variables $Y_1, Y_2, \\ldots, Y_k$ (e.g., different health metrics).\n",
        "\n",
        "2.  Tree Construction\n",
        "\n",
        "  -   `Splitting Rule`: Each tree in the forest splits the covariate space to maximize heterogeneity in treatment effects across all arms and outcomes. The splitting criterion optimizes a loss function that measures the quality of treatment effect estimates (e.g., variance of estimated effects).\n",
        "  -   `Multi-Arm`: For multiple treatments, the tree estimates treatment effects for each arm relative to a baseline (e.g., control) or pairwise differences.\n",
        "  -   `Multi-Outcome`: For multiple outcomes, the tree models correlations between outcomes, sharing information to improve estimation efficiency (e.g., using a joint loss function or covariance structure).\n",
        "  -   `Honest Splitting*` Uses separate data for splitting and estimation within each tree to reduce bias (a hallmark of GRF).\n",
        "\n",
        "3.  Treatment Effect Estimation\n",
        "\n",
        "  -   For each leaf node in a tree, the algorithm estimates treatment effects for each treatment arm and outcome using local observations.\n",
        "  -   `Multi-Arm`: Computes the effect of each treatment (e.g., $\\tau_j(X) = E[Y | W=j, X] - E[Y | W=0, X]$) for treatment $j$ vs. control).\n",
        "  -   `Multi-Outcome`: Estimates effects for each outcome (e.g., $\\tau_{j,k}(X)$ for treatment $j$ on outcome $k$), often modeling outcome correlations to improve precision.\n",
        "    -   Methods like local linear regression or moment-based estimation may be used within leaves to estimate effects.\n",
        "\n",
        "4.  Forest Aggregation\n",
        "\n",
        "  -   The forest averages predictions across many trees (typically hundreds or thousands) to produce robust estimates.\n",
        "  -   For a given covariate $X$, the forest outputs a vector of treatment effect estimates for each treatment arm and outcome, e.g., $\\hat{\\tau}(X) = [\\hat{\\tau}_{1,1}(X), \\hat{\\tau}_{1,2}(X), \\ldots, \\hat{\\tau}_{j,k}(X)]$.\n",
        "  -   Variance estimates are also provided to assess uncertainty.\n",
        "\n",
        "5.  Handling Complexity\n",
        "\n",
        "  -   `Multi-Arm`: The forest balances comparisons across multiple treatments, reducing overfitting by sharing information across arms.\n",
        "  -   `Multi-Outcome`: Leverages correlations between outcomes (e.g., via covariance weighting) to improve efficiency, especially when outcomes are related (e.g., systolic and diastolic blood pressure).\n",
        "  -   `Nuisance Parameters`: Estimates propensity scores (probability of receiving each treatment) or outcome regressions to adjust for confounding, often using separate forests for these nuisance functions.\n",
        "\n",
        "6.  Output:\n",
        "\n",
        "  -   For each individual (defined by covariates $X$, the model provides:\n",
        "        -   Estimated treatment effects for each treatment arm and outcome.\n",
        "        -   Confidence intervals or standard errors for uncertainty.\n",
        "    -   Visualizations or summaries of heterogeneous effects (e.g., which subgroups benefit most from a specific treatment).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A2tB_TxOs0nQ"
      },
      "source": [
        "### Key Differences from Standard Causal Forest\n",
        "\n",
        "-   `Standard Causal Forest`: Handles one treatment (binary or continuous) and one outcome, estimating a single treatment effect per individual.\n",
        "-   `Multi-Arm/Multi-Outcome Causal Forest`:\n",
        "    -   Models multiple treatments (e.g., multiple drugs) and/or multiple outcomes (e.g., multiple health metrics).\n",
        "    -   Shares information across arms/outcomes to improve estimation efficiency.\n",
        "    -   Uses a joint objective function to optimize splits for all treatments and outcomes simultaneously.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bIBhNo81s-Nt"
      },
      "source": [
        "### Advantages\n",
        "\n",
        "-   Handles complex experiments with multiple treatments and outcomes.\n",
        "-   Captures heterogeneity in treatment effects across subgroups.\n",
        "-   Robust to non-linear relationships and high-dimensional covariates.\n",
        "-   Improves efficiency by sharing information across arms/outcomes.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aT54GhcZvKS_"
      },
      "source": [
        "### Limitations\n",
        "\n",
        "-   Requires sufficient sample size for each treatment arm and outcome.\n",
        "-   Assumes unconfoundedness (no unmeasured confounders) unless combined with other methods (e.g., instrumental variables).\n",
        "-   Computationally intensive for large datasets or many outcomes.\n",
        "-   Interpretability can be challenging due to complex output (multiple effects per individual)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bh7jEhGCLDZA"
      },
      "source": [
        "## Multi-arm/multi-outcome Causal Forest with Python\n",
        "\n",
        "The Generalized Random Forest (GRF) package, which implements the multi-arm/multi-outcome causal forest, is primarily available in R and does not have a direct, officially supported Python implementation in the {grf} package. However, Python users can leverage alternative libraries like {econml}, which provides a `CausalForest` class that supports `multi-arm` and `multi-outcome` causal inference. Below, I outline how to perform a multi-arm/multi-outcome causal forest analysis in Python using the {econml} package, based on available resources and the conceptual framework of causal forests\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IPobetr0zFC5"
      },
      "source": [
        "### Load and Prepare the Lung Dataset\n",
        "\n",
        "The lung dataset includes survival data for lung cancer patients. Since lung lacks a treatment variable and multiple outcomes, we:\n",
        "\n",
        "-   Simulates a multi-arm `treatment` variable with three levels: `placebo`, `A`, and `B` and Assigns probabilities (40% placebo, 30% A, 30% B) for each treatment.\n",
        "\n",
        "-   Simulates a binary secondary outcome (e.g., `health_status`, 1 = yes, 0 = no) with treatment-dependent probabilities.\n",
        "\n",
        "-   Use log-transformed survival time (`log_time`) as the primary outcome to ensure numerical stability\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        },
        "id": "yhPSobMMMF2-",
        "outputId": "5a537a24-5241-495f-9bdd-ce1e9785fff2"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>inst</th>\n",
              "      <th>time</th>\n",
              "      <th>status</th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>ph.ecog</th>\n",
              "      <th>ph.karno</th>\n",
              "      <th>pat.karno</th>\n",
              "      <th>meal.cal</th>\n",
              "      <th>wt.loss</th>\n",
              "      <th>treatment</th>\n",
              "      <th>health_status</th>\n",
              "      <th>log_time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3.0</td>\n",
              "      <td>306</td>\n",
              "      <td>2</td>\n",
              "      <td>74</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>90.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>1175.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>A</td>\n",
              "      <td>0</td>\n",
              "      <td>5.723585</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3.0</td>\n",
              "      <td>455</td>\n",
              "      <td>2</td>\n",
              "      <td>68</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>90.0</td>\n",
              "      <td>90.0</td>\n",
              "      <td>1225.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>placebo</td>\n",
              "      <td>0</td>\n",
              "      <td>6.120297</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3.0</td>\n",
              "      <td>1010</td>\n",
              "      <td>1</td>\n",
              "      <td>56</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>90.0</td>\n",
              "      <td>90.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>15.0</td>\n",
              "      <td>placebo</td>\n",
              "      <td>0</td>\n",
              "      <td>6.917706</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5.0</td>\n",
              "      <td>210</td>\n",
              "      <td>2</td>\n",
              "      <td>57</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>90.0</td>\n",
              "      <td>60.0</td>\n",
              "      <td>1150.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>A</td>\n",
              "      <td>0</td>\n",
              "      <td>5.347108</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.0</td>\n",
              "      <td>883</td>\n",
              "      <td>2</td>\n",
              "      <td>60</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>90.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>B</td>\n",
              "      <td>0</td>\n",
              "      <td>6.783325</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   inst  time  status  age  sex  ph.ecog  ph.karno  pat.karno  meal.cal  \\\n",
              "0   3.0   306       2   74    1      1.0      90.0      100.0    1175.0   \n",
              "1   3.0   455       2   68    1      0.0      90.0       90.0    1225.0   \n",
              "2   3.0  1010       1   56    1      0.0      90.0       90.0       NaN   \n",
              "3   5.0   210       2   57    1      1.0      90.0       60.0    1150.0   \n",
              "4   1.0   883       2   60    1      0.0     100.0       90.0       NaN   \n",
              "\n",
              "   wt.loss treatment  health_status  log_time  \n",
              "0      NaN         A              0  5.723585  \n",
              "1     15.0   placebo              0  6.120297  \n",
              "2     15.0   placebo              0  6.917706  \n",
              "3     11.0         A              0  5.347108  \n",
              "4      0.0         B              0  6.783325  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of X: (227, 3)\n",
            "Shape of W: (227,)\n",
            "Shape of Y: (227, 2)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Load the lung dataset\n",
        "url = \"https://github.com/zia207/r-colab/raw/main/Data/Machine_Learning/lung.csv\"\n",
        "lung_data = pd.read_csv(url)\n",
        "\n",
        "# Filter the DataFrame\n",
        "lung_data = lung_data.dropna(subset=['age', 'sex', 'ph.ecog'])\n",
        "\n",
        "# Create the 'treatment' column\n",
        "np.random.seed(123) # for reproducibility\n",
        "treatment_arms = ['placebo', 'A', 'B']\n",
        "treatment_probs = [0.4, 0.3, 0.3]\n",
        "lung_data['treatment'] = np.random.choice(treatment_arms, size=len(lung_data), p=treatment_probs)\n",
        "\n",
        "# Create the 'health_status' column\n",
        "# Simulate probabilities based on treatment: base_prob + effect_A * (treatment == 'A') + effect_B * (treatment == 'B')\n",
        "base_prob = 0.3\n",
        "effect_A = 0.1\n",
        "effect_B = 0.15\n",
        "prob_health_status = base_prob + effect_A * (lung_data['treatment'] == 'A') + effect_B * (lung_data['treatment'] == 'B')\n",
        "lung_data['health_status'] = np.random.binomial(1, prob_health_status, size=len(lung_data))\n",
        "\n",
        "# Create the 'log_time' column\n",
        "lung_data['log_time'] = np.log(lung_data['time'])\n",
        "\n",
        "# Define X, W, Y\n",
        "X = lung_data[['age', 'sex', 'ph.ecog']].values\n",
        "W = lung_data['treatment'].values\n",
        "Y = lung_data[['log_time', 'health_status']].values\n",
        "\n",
        "# Ensure Y has correct column names (for later reference if needed, though numpy array doesn't store names like pandas)\n",
        "# We'll keep track of names conceptually or use pandas for operations where names are important.\n",
        "# For the numpy array Y, we can add a comment or store names separately.\n",
        "# Y_colnames = ['log_time', 'health_status']\n",
        "\n",
        "display(lung_data.head())\n",
        "print(\"Shape of X:\", X.shape)\n",
        "print(\"Shape of W:\", W.shape)\n",
        "print(\"Shape of Y:\", Y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fvc1_moAMYNP",
        "outputId": "755f62fd-7e33-41f5-f711-6e43bd7413ee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of X_train: (181, 3)\n",
            "Shape of X_test: (46, 3)\n",
            "Shape of W_train: (181,)\n",
            "Shape of W_test: (46,)\n",
            "Shape of Y_train: (181, 2)\n",
            "Shape of Y_test: (46, 2)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split into training and test sets\n",
        "X_train, X_test, W_train, W_test, Y_train, Y_test = train_test_split(\n",
        "    X, W, Y, test_size=0.2, random_state=123\n",
        ")\n",
        "\n",
        "# Print the shapes\n",
        "print(\"Shape of X_train:\", X_train.shape)\n",
        "print(\"Shape of X_test:\", X_test.shape)\n",
        "print(\"Shape of W_train:\", W_train.shape)\n",
        "print(\"Shape of W_test:\", W_test.shape)\n",
        "print(\"Shape of Y_train:\", Y_train.shape)\n",
        "print(\"Shape of Y_test:\", Y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p0OqMvCrgZ8a",
        "outputId": "b5dd12a6-2c7a-4754-a241-a45c734df725"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "econml library is available for research.\n",
            "Research suggests econml's CausalForestDML and ORF can handle multi-arm treatments.\n"
          ]
        }
      ],
      "source": [
        "import econml\n",
        "print(\"econml library is available for research.\")\n",
        "\n",
        "# Placeholder for research findings - this would typically involve\n",
        "# reading econml documentation online or using help()\n",
        "# Example check for relevant classes/functions in econml:\n",
        "# help(econml.dml)\n",
        "# help(econml.metalearners)\n",
        "# help(econml.orf) # May contain multi-treatment options\n",
        "\n",
        "# Based on external research (as the notebook environment doesn't allow web browsing):\n",
        "# econml's CausalForestDML supports multiple treatments. The 'W' parameter\n",
        "# in fit() can be a multi-column matrix where each column represents\n",
        "# a binary treatment indicator, or a single column with multiple discrete values.\n",
        "# This allows for multi-arm treatment scenarios.\n",
        "# It estimates the Conditional Average Treatment Effect (CATE) for each treatment\n",
        "# relative to a baseline (usually the first treatment value encountered unless specified).\n",
        "# It can handle multiple outcomes by either fitting a separate model for each outcome\n",
        "# or by using multi-output regressors/classifiers internally if supported by the base learners.\n",
        "# econml's Orthogonal Random Forest (ORF) also supports multiple treatments.\n",
        "\n",
        "print(\"Research suggests econml's CausalForestDML and ORF can handle multi-arm treatments.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "12NpLJZFglCj"
      },
      "source": [
        "### Train the Multi-arm/Multi-outcome Causal Forest\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eq3MKNguggj0",
        "outputId": "c300592e-edef-476f-f05a-3104cece3167"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Causal Forest models for log_time and health_status trained successfully using encoded treatment.\n"
          ]
        }
      ],
      "source": [
        "from econml.dml import CausalForestDML\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
        "\n",
        "# Instantiate CausalForestDML models for each outcome\n",
        "macf_log_time = CausalForestDML()\n",
        "macf_health_status = CausalForestDML()\n",
        "\n",
        "# Encode the treatment variable W_train\n",
        "label_encoder = LabelEncoder()\n",
        "W_train_encoded = label_encoder.fit_transform(W_train)\n",
        "\n",
        "# Fit the models to the training data using the encoded treatment variable\n",
        "# For log_time, Y_train[:, 0] is the outcome column (Y)\n",
        "# W_train_encoded is the encoded treatment column (T)\n",
        "# X_train is the covariates (X)\n",
        "macf_log_time.fit(Y=Y_train[:, 0], T=W_train_encoded, X=X_train)\n",
        "\n",
        "# For health_status, Y_train[:, 1] is the outcome column (Y)\n",
        "# W_train_encoded is the encoded treatment column (T)\n",
        "# X_train is the covariates (X)\n",
        "macf_health_status.fit(Y=Y_train[:, 1], T=W_train_encoded, X=X_train)\n",
        "\n",
        "print(\"Causal Forest models for log_time and health_status trained successfully using encoded treatment.\")\n",
        "\n",
        "# Store the encoder for later use in prediction\n",
        "treatment_encoder = label_encoder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SXoS24GIhCLO"
      },
      "source": [
        "### Prediction and Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iv0rri02hFuY",
        "outputId": "6bc4407a-4124-4a66-912d-e233740106a3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predicted treatment effects for log_time on the test set (shape: num_test_samples x num_treatments-1):\n",
            "(46,)\n",
            "\n",
            "Predicted treatment effects for health_status on the test set (shape: num_test_samples x num_treatments-1):\n",
            "(46,)\n"
          ]
        }
      ],
      "source": [
        "# Predict treatment effects on the test set\n",
        "# Use the trained models (macf_log_time and macf_health_status) and the test covariates (X_test)\n",
        "# The effect method of CausalForestDML returns the estimated treatment effects (CATE)\n",
        "# for each treatment relative to the baseline treatment (which is typically the first encountered\n",
        "# encoded treatment level, usually 0 after LabelEncoding, corresponding to 'placebo' in our case).\n",
        "\n",
        "tau_hat_log_time = macf_log_time.effect(X_test)\n",
        "tau_hat_health_status = macf_health_status.effect(X_test)\n",
        "\n",
        "print(\"Predicted treatment effects for log_time on the test set (shape: num_test_samples x num_treatments-1):\")\n",
        "print(tau_hat_log_time.shape)\n",
        "print(\"\\nPredicted treatment effects for health_status on the test set (shape: num_test_samples x num_treatments-1):\")\n",
        "print(tau_hat_health_status.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7KgHx7kY9EEg"
      },
      "source": [
        "### Calculate Doubly Robust Average Treatment Effects (AIPW)\n",
        "\n",
        "We compute the average treatment effects (ATE) for each arm relative to \"placebo\" using the doubly robust Augmented Inverse Propensity Weighting (AIPW) method  similar to R package {grf}."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cp7YIpT5iS1Z",
        "outputId": "4cff0374-c5e2-4e13-8d8d-4eea1a1246f0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average Treatment Effects for log_time:\n",
            "  A - placebo: 0.279552\n",
            "  B - placebo: 0.139776\n",
            "\n",
            "Average Treatment Effects for health_status:\n",
            "  A - placebo: 0.127971\n",
            "  B - placebo: 0.063985\n"
          ]
        }
      ],
      "source": [
        "# Retrieve the encoded numerical values for 'placebo', 'A', and 'B'\n",
        "encoded_placebo = treatment_encoder.transform(['placebo'])[0]\n",
        "encoded_A = treatment_encoder.transform(['A'])[0]\n",
        "encoded_B = treatment_encoder.transform(['B'])[0]\n",
        "\n",
        "# Calculate the Average Treatment Effect (ATE) for 'A' vs 'placebo' for the log_time outcome\n",
        "# Call the effect() method with T0 as encoded_placebo and T1 as encoded_A\n",
        "tau_hat_log_time_A_vs_placebo = macf_log_time.effect(X_test, T0=encoded_placebo, T1=encoded_A)\n",
        "# Compute the mean of the returned array to get the ATE\n",
        "ate_log_time_A_vs_placebo = np.mean(tau_hat_log_time_A_vs_placebo)\n",
        "\n",
        "# Calculate the ATE for 'B' vs 'placebo' for the log_time outcome\n",
        "# Call the effect() method with T0 as encoded_placebo and T1 as encoded_B\n",
        "tau_hat_log_time_B_vs_placebo = macf_log_time.effect(X_test, T0=encoded_placebo, T1=encoded_B)\n",
        "# Compute the mean of the returned array to get the ATE\n",
        "ate_log_time_B_vs_placebo = np.mean(tau_hat_log_time_B_vs_placebo)\n",
        "\n",
        "# Repeat for the health_status outcome\n",
        "# Calculate the ATE for 'A' vs 'placebo' for the health_status outcome\n",
        "tau_hat_health_status_A_vs_placebo = macf_health_status.effect(X_test, T0=encoded_placebo, T1=encoded_A)\n",
        "ate_health_status_A_vs_placebo = np.mean(tau_hat_health_status_A_vs_placebo)\n",
        "\n",
        "# Calculate the ATE for 'B' vs 'placebo' for the health_status outcome\n",
        "tau_hat_health_status_B_vs_placebo = macf_health_status.effect(X_test, T0=encoded_placebo, T1=encoded_B)\n",
        "ate_health_status_B_vs_placebo = np.mean(tau_hat_health_status_B_vs_placebo)\n",
        "\n",
        "# Print the calculated ATEs\n",
        "print(\"Average Treatment Effects for log_time:\")\n",
        "print(f\"  A - placebo: {ate_log_time_A_vs_placebo:.6f}\")\n",
        "print(f\"  B - placebo: {ate_log_time_B_vs_placebo:.6f}\")\n",
        "\n",
        "print(\"\\nAverage Treatment Effects for health_status:\")\n",
        "print(f\"  A - placebo: {ate_health_status_A_vs_placebo:.6f}\")\n",
        "print(f\"  B - placebo: {ate_health_status_B_vs_placebo:.6f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Uc9PcoOgJjF"
      },
      "source": [
        "### Plot Variable Importance\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "04QVrhr19V9R",
        "outputId": "7ecc31fa-f026-4fcf-98a7-b002dc0d2e73"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Outcome model for log_time not found or does not have feature_importances_.\n",
            "Outcome model for health_status not found or does not have feature_importances_.\n",
            "Feature importances from base outcome models were not accessible for plotting.\n"
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "outcome_model_log_time = getattr(macf_log_time, '_model_y', None)\n",
        "outcome_model_health_status = getattr(macf_health_status, '_model_y', None)\n",
        "\n",
        "log_time_importances = None\n",
        "health_status_importances = None\n",
        "\n",
        "# Check if the outcome models were found and have feature_importances_\n",
        "if outcome_model_log_time is not None and hasattr(outcome_model_log_time, 'feature_importances_'):\n",
        "    log_time_importances = outcome_model_log_time.feature_importances_\n",
        "    print(\"Feature importances found for log_time outcome model.\")\n",
        "elif outcome_model_log_time is not None and hasattr(outcome_model_log_time, 'estimators_'):\n",
        "    # If _model_y is a forest-like object (e.g., RandomForestRegressor),\n",
        "    # its estimators_ (individual trees) might have feature_importances_.\n",
        "    # We can average them or check the top-level attribute.\n",
        "    # Let's check the top-level attribute first.\n",
        "     print(\"Outcome model for log_time found, but no direct feature_importances_ attribute.\")\n",
        "     # As a fallback, if the base model is a forest, we might look into its components\n",
        "     # but this gets deep into implementation details.\n",
        "     # Let's assume if _model_y exists, it's the right place to look for importances if available.\n",
        "     # If the above didn't find it, let's try accessing a potential internal forest object\n",
        "     # which is less reliable as an API.\n",
        "     # macf_log_time.model_y_x # Model for Y | X\n",
        "     # macf_log_time.model_t_x # Model for T | X\n",
        "     # None of these directly give importance for Y | X, T that the CausalForestDML uses.\n",
        "     # The `_model_y` was the most plausible attribute found in docs/examples for the Y|X,T model.\n",
        "     # If it doesn't have feature_importances_, it might not be directly exposed or calculated this way.\n",
        "else:\n",
        "     print(\"Outcome model for log_time not found or does not have feature_importances_.\")\n",
        "\n",
        "\n",
        "if outcome_model_health_status is not None and hasattr(outcome_model_health_status, 'feature_importances_'):\n",
        "    health_status_importances = outcome_model_health_status.feature_importances_\n",
        "    print(\"Feature importances found for health_status outcome model.\")\n",
        "elif outcome_model_health_status is not None and hasattr(outcome_model_health_status, 'estimators_'):\n",
        "     print(\"Outcome model for health_status found, but no direct feature_importances_ attribute.\")\n",
        "else:\n",
        "    print(\"Outcome model for health_status not found or does not have feature_importances_.\")\n",
        "\n",
        "# Proceed to plotting only if importances were found\n",
        "if log_time_importances is not None or health_status_importances is not None:\n",
        "    # Get original covariate names\n",
        "    covariate_names = ['age', 'sex', 'ph.ecog'] # Assuming X columns correspond to these\n",
        "\n",
        "    # Plot for log_time outcome\n",
        "    if log_time_importances is not None and len(log_time_importances) == len(covariate_names):\n",
        "        var_imp_df_log_time = pd.DataFrame({\n",
        "          'Variable': covariate_names,\n",
        "          'Importance': log_time_importances\n",
        "        })\n",
        "\n",
        "        plt.figure(figsize=(8, 5))\n",
        "        sns.barplot(x='Importance', y='Variable', data=var_imp_df_log_time.sort_values('Importance', ascending=False), palette=\"viridis\")\n",
        "        plt.title(\"Variable Importance for log_time (Outcome Model)\")\n",
        "        plt.xlabel(\"Importance\")\n",
        "        plt.ylabel(\"Variable\")\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "    elif log_time_importances is not None:\n",
        "         print(f\"Mismatch in importance length ({len(log_time_importances)}) and covariate names ({len(covariate_names)}) for log_time.\")\n",
        "    else:\n",
        "        print(\"Variable importance data not available for plotting log_time.\")\n",
        "\n",
        "\n",
        "    # Plot for health_status outcome\n",
        "    if health_status_importances is not None and len(health_status_importances) == len(covariate_names):\n",
        "        var_imp_df_health_status = pd.DataFrame({\n",
        "          'Variable': covariate_names,\n",
        "          'Importance': health_status_importances\n",
        "        })\n",
        "\n",
        "        plt.figure(figsize=(8, 5))\n",
        "        sns.barplot(x='Importance', y='Variable', data=var_imp_df_health_status.sort_values('Importance', ascending=False), palette=\"viridis\")\n",
        "        plt.title(\"Variable Importance for health_status (Outcome Model)\")\n",
        "        plt.xlabel(\"Importance\")\n",
        "        plt.ylabel(\"Variable\")\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "    elif health_status_importances is not None:\n",
        "        print(f\"Mismatch in importance length ({len(health_status_importances)}) and covariate names ({len(covariate_names)}) for health_status.\")\n",
        "    else:\n",
        "        print(\"Variable importance data not available for plotting health_status.\")\n",
        "\n",
        "else:\n",
        "    print(\"Feature importances from base outcome models were not accessible for plotting.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0QaY9XkzH6NQ"
      },
      "source": [
        "## Multi-arm/multi-outcome Causal Forest with `multi_arm_causal_forest()` function\n",
        "\n",
        "Alternatively, we can create a Python implementation similar to R's `multi_arm_causal_forest()` of the {grf} package. This will include fitting the model, calculating doubly robust average treatment effects, and plotting variable importance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Here's a step-by-step explanation of the `multi_arm_causal_forest()` function:\n",
        "\n",
        "1. **Input Preparation**:\n",
        "   - Takes pre-split training/test data (X, W, Y for both sets)\n",
        "   - Assumes treatments (W) are categorical and outcomes (Y) can be multi-dimensional\n",
        "\n",
        "2. **Treatment Encoding**:\n",
        "   - One-hot encodes treatment assignments (W) into binary matrices\n",
        "   - Stores original treatment names for reference\n",
        "\n",
        "3. **Model Training**:\n",
        "   - Trains separate outcome models for each treatment-outcome combination\n",
        "   - Uses Random Forest regressors for continuous outcomes\n",
        "   - Trains a propensity model (Random Forest) to estimate treatment probabilities\n",
        "\n",
        "4. **Doubly Robust Scores**:\n",
        "   - Calculates AIPW (Augmented Inverse Probability Weighting) scores:\n",
        "     - Predicts potential outcomes under each treatment\n",
        "     - Adjusts for treatment assignment probabilities\n",
        "     - Combines models to reduce bias in effect estimation\n",
        "\n",
        "5. **Treatment Effects**:\n",
        "   - Computes Average Treatment Effects (ATE) between all treatment pairs\n",
        "   - For each outcome, compares all possible treatment combinations\n",
        "\n",
        "6. **Variable Importance**:\n",
        "   - Extracts feature importance from the outcome models\n",
        "   - Provides importance scores for each covariate-outcome pair\n",
        "\n",
        "7. **Predictions**:\n",
        "   - Generates test set predictions for all treatment-outcome combinations\n",
        "\n",
        "8. **Output**:\n",
        "   - Returns:\n",
        "     - ATE results as a DataFrame\n",
        "     - Variable importance as a DataFrame\n",
        "     - Test predictions\n",
        "     - Treatment and outcome names for reference\n",
        "\n",
        "Key Features:\n",
        "- Handles multiple treatments and multiple outcomes\n",
        "- Uses doubly robust estimation for unbiased effect sizes\n",
        "- Provides interpretable variable importance\n",
        "- Returns organized DataFrames for easy analysis\n",
        "\n",
        "The function focuses purely on causal estimation after data preparation, making it modular and reusable across different datasets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "def multi_arm_causal_forest(X_train, W_train, Y_train, X_test, W_test, Y_test, num_trees=2000, min_node_size=5):\n",
        "    \"\"\"\n",
        "    Multi-arm causal forest implementation without data splitting/processing.\n",
        "    \n",
        "    Parameters:\n",
        "    X_train, X_test: Training and test covariates\n",
        "    W_train, W_test: Training and test treatment assignments\n",
        "    Y_train, Y_test: Training and test outcomes\n",
        "    num_trees: Number of trees in the forest\n",
        "    min_node_size: Minimum node size\n",
        "    \n",
        "    Returns:\n",
        "    Dictionary containing:\n",
        "    - ate_df: DataFrame of Average Treatment Effects\n",
        "    - var_imp_df: DataFrame of Variable Importance\n",
        "    - test_predictions: Predictions on test set\n",
        "    \"\"\"\n",
        "    \n",
        "    # One-hot encode treatments\n",
        "    encoder = OneHotEncoder()\n",
        "    W_train_encoded = encoder.fit_transform(W_train.reshape(-1, 1)).toarray()\n",
        "    W_test_encoded = encoder.transform(W_test.reshape(-1, 1)).toarray()\n",
        "    treatment_names = encoder.categories_[0]\n",
        "    \n",
        "    num_treatments = len(treatment_names)\n",
        "    num_outcomes = Y_train.shape[1] if len(Y_train.shape) > 1 else 1\n",
        "    \n",
        "    # Train outcome models (one per treatment per outcome)\n",
        "    outcome_models = {}\n",
        "    for t_idx, t in enumerate(treatment_names):\n",
        "        mask = (W_train == t)\n",
        "        X_t = X_train[mask]\n",
        "        \n",
        "        for o_idx in range(num_outcomes):\n",
        "            Y_t = Y_train[mask, o_idx] if num_outcomes > 1 else Y_train[mask]\n",
        "            \n",
        "            model = RandomForestRegressor(\n",
        "                n_estimators=num_trees,\n",
        "                min_samples_leaf=min_node_size,\n",
        "                random_state=42\n",
        "            )\n",
        "            model.fit(X_t, Y_t)\n",
        "            outcome_models[(t_idx, o_idx)] = model\n",
        "    \n",
        "    # Train propensity model\n",
        "    propensity_model = RandomForestRegressor(\n",
        "        n_estimators=num_trees,\n",
        "        min_samples_leaf=min_node_size,\n",
        "        random_state=42\n",
        "    )\n",
        "    propensity_model.fit(X_train, W_train_encoded)\n",
        "    \n",
        "    # Get propensity scores\n",
        "    propensities_train = propensity_model.predict(X_train)\n",
        "    propensities_test = propensity_model.predict(X_test)\n",
        "    \n",
        "    # Calculate doubly robust scores (AIPW)\n",
        "    def calculate_dr_scores(X, W, Y, propensities):\n",
        "        dr_scores = np.zeros((len(X), num_treatments, num_outcomes))\n",
        "        \n",
        "        for t_idx in range(num_treatments):\n",
        "            p_t = propensities[:, t_idx]\n",
        "            \n",
        "            for o_idx in range(num_outcomes):\n",
        "                Y_vals = Y[:, o_idx] if num_outcomes > 1 else Y\n",
        "                mu_t = outcome_models[(t_idx, o_idx)].predict(X)\n",
        "                indicator = (W == treatment_names[t_idx])\n",
        "                dr_scores[:, t_idx, o_idx] = mu_t + indicator * (Y_vals - mu_t) / np.clip(p_t, 1e-3, 1-1e-3)\n",
        "        \n",
        "        return dr_scores\n",
        "    \n",
        "    dr_test = calculate_dr_scores(X_test, W_test, Y_test, propensities_test)\n",
        "    \n",
        "    # Calculate average treatment effects\n",
        "    ate_results = []\n",
        "    for o_idx in range(num_outcomes):\n",
        "        outcome_name = f\"outcome_{o_idx}\" if num_outcomes > 1 else \"outcome\"\n",
        "        \n",
        "        for i in range(num_treatments):\n",
        "            for j in range(i+1, num_treatments):\n",
        "                ate_ij = np.mean(dr_test[:, j, o_idx] - dr_test[:, i, o_idx])\n",
        "                ate_results.append({\n",
        "                    'Outcome': outcome_name,\n",
        "                    'Comparison': f\"{treatment_names[j]} vs {treatment_names[i]}\",\n",
        "                    'ATE': ate_ij\n",
        "                })\n",
        "    \n",
        "    # Calculate variable importance\n",
        "    var_imp_results = []\n",
        "    feature_names = ['age', 'sex', 'ph.ecog']  # Should be passed if not using lung data\n",
        "    \n",
        "    for o_idx in range(num_outcomes):\n",
        "        outcome_name = f\"outcome_{o_idx}\" if num_outcomes > 1 else \"outcome\"\n",
        "        model = outcome_models[(0, o_idx)]\n",
        "        importances = model.feature_importances_\n",
        "        \n",
        "        for feat_idx, imp in enumerate(importances):\n",
        "            var_imp_results.append({\n",
        "                'Outcome': outcome_name,\n",
        "                'Feature': feature_names[feat_idx],\n",
        "                'Importance': imp\n",
        "            })\n",
        "    \n",
        "    # Generate test predictions\n",
        "    test_predictions = {}\n",
        "    for t_idx, t in enumerate(treatment_names):\n",
        "        for o_idx in range(num_outcomes):\n",
        "            outcome_name = f\"outcome_{o_idx}\" if num_outcomes > 1 else \"outcome\"\n",
        "            key = f\"{t}_{outcome_name}\"\n",
        "            test_predictions[key] = outcome_models[(t_idx, o_idx)].predict(X_test)\n",
        "    \n",
        "    return {\n",
        "        'ate_df': pd.DataFrame(ate_results),\n",
        "        'var_imp_df': pd.DataFrame(var_imp_results),\n",
        "        'test_predictions': pd.DataFrame(test_predictions),\n",
        "        'treatment_names': treatment_names,\n",
        "        'outcome_names': ['log_time', 'health_status'] if num_outcomes > 1 else ['outcome']\n",
        "    }\n",
        "\n",
        "def plot_results(results):\n",
        "    \"\"\"Plot variable importance and display results.\"\"\"\n",
        "    # Variable importance plot\n",
        "    fig, axes = plt.subplots(1, len(results['outcome_names']), figsize=(12, 5))\n",
        "    if len(results['outcome_names']) == 1:\n",
        "        axes = [axes]\n",
        "    \n",
        "    for i, outcome in enumerate(results['outcome_names']):\n",
        "        df = results['var_imp_df'][results['var_imp_df']['Outcome'] == (f\"outcome_{i}\" if len(results['outcome_names']) > 1 else \"outcome\")]\n",
        "        df = df.sort_values('Importance')\n",
        "        axes[i].barh(df['Feature'], df['Importance'])\n",
        "        axes[i].set_title(f'Variable Importance - {outcome}')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    # Display ATE results using print instead of display\n",
        "    print(\"\\nAverage Treatment Effects (AIPW):\")\n",
        "    print(results['ate_df'].to_string())\n",
        "    \n",
        "    # Show first few test predictions\n",
        "    print(\"\\nTest Set Predictions (first 5 samples):\")\n",
        "    print(results['test_predictions'].head().to_string())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EDgTlysSMx5g"
      },
      "source": [
        "### Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        },
        "id": "vdn2mHGLMAQi",
        "outputId": "a73df70e-af14-4204-903b-3826508c0c98"
      },
      "outputs": [],
      "source": [
        "# Load and prepare the data\n",
        "url = \"https://github.com/zia207/r-colab/raw/main/Data/Machine_Learning/lung.csv\"\n",
        "lung_data = pd.read_csv(url)\n",
        "\n",
        "# Filter the DataFrame\n",
        "lung_data = lung_data.dropna(subset=['age', 'sex', 'ph.ecog'])\n",
        "\n",
        "# Create the 'treatment' column\n",
        "np.random.seed(123) # for reproducibility\n",
        "treatment_arms = ['placebo', 'A', 'B']\n",
        "treatment_probs = [0.4, 0.3, 0.3]\n",
        "lung_data['treatment'] = np.random.choice(treatment_arms, size=len(lung_data), p=treatment_probs)\n",
        "\n",
        "# Create the 'health_status' column\n",
        "base_prob = 0.3\n",
        "effect_A = 0.1\n",
        "effect_B = 0.15\n",
        "prob_health_status = base_prob + effect_A * (lung_data['treatment'] == 'A') + effect_B * (lung_data['treatment'] == 'B')\n",
        "lung_data['health_status'] = np.random.binomial(1, prob_health_status, size=len(lung_data))\n",
        "\n",
        "# Create the 'log_time' column\n",
        "lung_data['log_time'] = np.log(lung_data['time'])\n",
        "\n",
        "# Define X, W, Y\n",
        "X = lung_data[['age', 'sex', 'ph.ecog']].values\n",
        "W = lung_data['treatment'].values\n",
        "Y = lung_data[['log_time', 'health_status']].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kIlth8UhModj",
        "outputId": "c907fdff-cb03-480c-e576-08ceb1aded20"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of X_train: (181, 3)\n",
            "Shape of X_test: (46, 3)\n",
            "Shape of W_train: (181,)\n",
            "Shape of W_test: (46,)\n",
            "Shape of Y_train: (181, 2)\n",
            "Shape of Y_test: (46, 2)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split into training and test sets\n",
        "X_train, X_test, W_train, W_test, Y_train, Y_test = train_test_split(\n",
        "    X, W, Y, test_size=0.2, random_state=123\n",
        ")\n",
        "\n",
        "# Print the shapes\n",
        "print(\"Shape of X_train:\", X_train.shape)\n",
        "print(\"Shape of X_test:\", X_test.shape)\n",
        "print(\"Shape of W_train:\", W_train.shape)\n",
        "print(\"Shape of W_test:\", W_test.shape)\n",
        "print(\"Shape of Y_train:\", Y_train.shape)\n",
        "print(\"Shape of Y_test:\", Y_test.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wSpVMNw7M1UH"
      },
      "source": [
        "### Train Multi-arm Causal_Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WnO-HKeRNDpI",
        "outputId": "47a10897-81c3-4518-c9f0-d381d02015bf"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1200x500 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average Treatment Effects (AIPW):\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Outcome</th>\n",
              "      <th>Comparison</th>\n",
              "      <th>ATE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>outcome_0</td>\n",
              "      <td>B vs A</td>\n",
              "      <td>0.011760</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>outcome_0</td>\n",
              "      <td>placebo vs A</td>\n",
              "      <td>-0.263888</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>outcome_0</td>\n",
              "      <td>placebo vs B</td>\n",
              "      <td>-0.275647</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>outcome_1</td>\n",
              "      <td>B vs A</td>\n",
              "      <td>-0.231666</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>outcome_1</td>\n",
              "      <td>placebo vs A</td>\n",
              "      <td>0.019756</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>outcome_1</td>\n",
              "      <td>placebo vs B</td>\n",
              "      <td>0.251423</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     Outcome    Comparison       ATE\n",
              "0  outcome_0        B vs A  0.011760\n",
              "1  outcome_0  placebo vs A -0.263888\n",
              "2  outcome_0  placebo vs B -0.275647\n",
              "3  outcome_1        B vs A -0.231666\n",
              "4  outcome_1  placebo vs A  0.019756\n",
              "5  outcome_1  placebo vs B  0.251423"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test Set Predictions (first 5 samples):\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>A_outcome_0</th>\n",
              "      <th>A_outcome_1</th>\n",
              "      <th>B_outcome_0</th>\n",
              "      <th>B_outcome_1</th>\n",
              "      <th>placebo_outcome_0</th>\n",
              "      <th>placebo_outcome_1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.660590</td>\n",
              "      <td>0.315100</td>\n",
              "      <td>5.210497</td>\n",
              "      <td>0.390598</td>\n",
              "      <td>5.591504</td>\n",
              "      <td>0.144341</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5.584289</td>\n",
              "      <td>0.352231</td>\n",
              "      <td>5.034483</td>\n",
              "      <td>0.662400</td>\n",
              "      <td>4.886838</td>\n",
              "      <td>0.410708</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5.364255</td>\n",
              "      <td>0.279721</td>\n",
              "      <td>5.208544</td>\n",
              "      <td>0.427713</td>\n",
              "      <td>5.501072</td>\n",
              "      <td>0.257715</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5.467306</td>\n",
              "      <td>0.296532</td>\n",
              "      <td>5.273451</td>\n",
              "      <td>0.388984</td>\n",
              "      <td>5.687326</td>\n",
              "      <td>0.166180</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.471690</td>\n",
              "      <td>0.296404</td>\n",
              "      <td>5.273451</td>\n",
              "      <td>0.388984</td>\n",
              "      <td>5.687804</td>\n",
              "      <td>0.099725</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   A_outcome_0  A_outcome_1  B_outcome_0  B_outcome_1  placebo_outcome_0  \\\n",
              "0     5.660590     0.315100     5.210497     0.390598           5.591504   \n",
              "1     5.584289     0.352231     5.034483     0.662400           4.886838   \n",
              "2     5.364255     0.279721     5.208544     0.427713           5.501072   \n",
              "3     5.467306     0.296532     5.273451     0.388984           5.687326   \n",
              "4     5.471690     0.296404     5.273451     0.388984           5.687804   \n",
              "\n",
              "   placebo_outcome_1  \n",
              "0           0.144341  \n",
              "1           0.410708  \n",
              "2           0.257715  \n",
              "3           0.166180  \n",
              "4           0.099725  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Run causal forest\n",
        "results = multi_arm_causal_forest(\n",
        "    X_train, W_train, Y_train,\n",
        "    X_test, W_test, Y_test,\n",
        "    num_trees=1000,\n",
        "    min_node_size=10\n",
        ")\n",
        "\n",
        "# Visualize results\n",
        "plot_results(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_j759RVMQMut"
      },
      "source": [
        "## Summary and Conclusion\n",
        "\n",
        "This notebook demonstrates two methods for implementing Multi-arm/Multi-outcome Causal Forests in Python: using the {econml} library and using the a  function`multi_arm_causal_forest()` similar to  {grf} R package.   While {econml} allows for handling multiple treatments and outcomes, the multi_arm_causal_forest()` function provides a more direct implementation with for calculating Average Treatment Effects (ATE) and plotting variable importance for multiple outcomes and treatment arms."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SaZTnZx3QPGI"
      },
      "source": [
        "## References\n",
        "\n",
        "1.  Wager, S., & Athey, S. (2018). Estimation and Inference of Heterogeneous Treatment Effects using Random Forests. JASA.\n",
        "\n",
        "2.  Athey, S., Tibshirani, J., & Wager, S. (2019). Generalized Random Forests. Ann. Statist.\n",
        "\n",
        "3.  Multi-arm/multi-outcome implementation available in grf R package"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyNHJ2khIRPZBt/MFMBSEtDt",
      "include_colab_link": true,
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "3.11.11",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
